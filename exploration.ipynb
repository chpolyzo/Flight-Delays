{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary Analysis\n",
    "## for KidKit\n",
    "\n",
    "## Data Wrangling\n",
    "\n",
    "> The original dataset reports domestic flights in the United States, including carriers, arrival and departure delays, and reasons for delays, from 1987 to 2008.\n",
    "\n",
    "> Data is available at the http://stat-computing.org/dataexpo/2009/the-data.html originally from https://www.transtats.bts.gov/OT_Delay/OT_DelayCause1.asp described in detail here https://www.transtats.bts.gov/Fields.asp?Table_ID=236"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import calendar\n",
    "import datetime as dt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_88 = pd.read_csv('1988.csv', nrows=None, encoding='latin-1')\n",
    "df_98 = pd.read_csv('1998.csv', nrows=None, encoding='latin-1')\n",
    "df_08 = pd.read_csv('2008.csv', nrows=None, encoding='latin-1')\n",
    "df_88.shape, df_98.shape, df_08.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the structure of our dataset?\n",
    "\n",
    "> We have selected three datasets to show how delays have evolved last thirty years in the aviation industry and perhaps get some insights about how to handle critical aviation operations linked to higher volume of flights This is because the first two datasets representing 5 million records each, demonstrate there has not been a significant change in flights volume. In the 2008 dataset a significant increase in the dataset records raise questions how this 30% increase has been handled by the actual aviation system and is so, there has been a direct impact in the passenger experience with respect to flight delays.\n",
    "\n",
    "### What are the main feature of interest in our dataset?\n",
    "\n",
    "> As explained before an increase in flight demand, must have altered aviation system's supply operations. Out of the 27 features - columns of our dataset We will focus on the delayed fligts or delays in general. However further investigation has to be performed with respect to cancelled flights, taxi  and local trasportation as well as including operations to final destinations. Other interesting information is provided and can be further eplored to improve passenger experience and further explore the success of innovative business models in the aviation industry. This can provide inderesting insights from the operations management prespective as well a comprehensive understanding of the operational cost for being idle. Carrier delay data can be thus analyzed, something we are not providing here.\n",
    "\n",
    "### What features in the dataset that will help support our investigation into our features of interest?\n",
    "\n",
    "> For the sake of this analyses we will be analysing 'Year', 'Month', 'DayofMonth', 'DayOfWeek', 'ArrDelay', 'CarrierDelay', 'WeatherDelay', 'NASDelay', 'SecurityDelay'and 'LateAircraftDelay'. 'ArrDelay' which is the delay of flights arrival in the case this is true is the sum in minutes of the following variables 'CarrierDelay' 'WeatherDelay', 'NASDelay', 'SecurityDelay' and 'LateAircraftDelay' aka, Carrier Delay, Weather Delay, National Airline System Delay, Security Delay and Late Aircraft Delay."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updated Dataset\n",
    "\n",
    "> We are now focussing on the part of the delayed flights so we have to drop from our dataset null values assuming empty records for delayed flights are the flights that arrive on time. Additionally, we only keep columns we are interested in, thus 'Year', 'Month', 'DayofMonth', 'DayOfWeek', 'ArrDelay', 'CarrierDelay', 'WeatherDelay', 'NASDelay', 'SecurityDelay'and 'LateAircraftDelay'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's visualize nulls in 1988 dataset\n",
    "plt.figure(figsize = (15,5))\n",
    "na_counts = df_88.isna().sum()\n",
    "base_color = sb.color_palette()[0]\n",
    "sb.barplot(na_counts.index.values, na_counts, color=base_color)\n",
    "locs, labels = plt.xticks() \n",
    "plt.xticks(np.arange(len(df_88.columns)), df_88.columns, rotation=90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's visualize nulls in 1998 dataset\n",
    "plt.figure(figsize = (15,5))\n",
    "na_counts = df_98.isna().sum()\n",
    "base_color = sb.color_palette()[0]\n",
    "sb.barplot(na_counts.index.values, na_counts, color=base_color)\n",
    "locs, labels = plt.xticks() \n",
    "plt.xticks(np.arange(len(df_98.columns)), df_98.columns, rotation=90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's visualize nulls in 2008 dataset\n",
    "plt.figure(figsize = (15,5))\n",
    "na_counts = df_98.isna().sum()\n",
    "base_color = sb.color_palette()[0]\n",
    "sb.barplot(na_counts.index.values, na_counts, color=base_color)\n",
    "locs, labels = plt.xticks() \n",
    "plt.xticks(np.arange(len(df_98.columns)), df_98.columns, rotation=90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's have a look at our fields\n",
    "df_98.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colums to keep\n",
    "fields = ['Year', 'Month', 'DayofMonth', 'DayOfWeek', 'ArrDelay', 'CarrierDelay',\n",
    "       'WeatherDelay', 'NASDelay', 'SecurityDelay', 'LateAircraftDelay' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns to drop \n",
    "#In this particular phase we are so lucky all our column names are the same in all datasets\n",
    "fields_to_drop = ['DepTime', 'CRSDepTime', 'ArrTime', 'CRSArrTime', 'UniqueCarrier', 'FlightNum', 'TailNum', \n",
    "                  'ActualElapsedTime', 'CRSElapsedTime', 'AirTime', 'DepDelay', 'Origin', 'Dest', 'Distance', \n",
    "                  'TaxiIn', 'TaxiOut', 'Cancelled', 'CancellationCode', 'Diverted']\n",
    "df_88.drop(fields_to_drop,axis=1,inplace=True)\n",
    "df_98.drop(fields_to_drop,axis=1,inplace=True)\n",
    "df_08.drop(fields_to_drop,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with null values in the 'ArrDelay' field in all datasets - We assume those values represent flights \n",
    "# arriving on time and check size of updated datasets\n",
    "\n",
    "df_88.dropna(subset = ['ArrDelay'], inplace = True)\n",
    "df_98.dropna(subset = ['ArrDelay'], inplace = True)\n",
    "df_08.dropna(subset = ['ArrDelay'], inplace = True)\n",
    "df_88.shape, df_98.shape, df_08.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shape of delayed flights in 1988\n",
    "df_88[df_88.ArrDelay > 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shape of delayed flights in 1998\n",
    "df_98[df_98.ArrDelay > 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shape of delayed flights in 2008\n",
    "df_08[df_08.ArrDelay > 0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate Exploration\n",
    "\n",
    "> In this section, investigate distributions of individual variables. If\n",
    "you see unusual points or outliers, take a deeper look to clean things up\n",
    "and prepare yourself to look at relationships between variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Make sure that, after every plot or related series of plots, that you\n",
    "include a Markdown cell with comments about what you observed, and what\n",
    "you plan on investigating next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discuss the distribution(s) of your variable(s) of interest. Were there any unusual points? Did you need to perform any transformations?\n",
    "\n",
    "> Your answer here!\n",
    "\n",
    "### Of the features you investigated, were there any unusual distributions? Did you perform any operations on the data to tidy, adjust, or change the form of the data? If so, why did you do this?\n",
    "\n",
    "> Your answer here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bivariate Exploration\n",
    "\n",
    "> In this section, investigate relationships between pairs of variables in your\n",
    "data. Make sure the variables that you cover here have been introduced in some\n",
    "fashion in the previous section (univariate exploration)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Talk about some of the relationships you observed in this part of the investigation. How did the feature(s) of interest vary with other features in the dataset?\n",
    "\n",
    "> Your answer here!\n",
    "\n",
    "### Did you observe any interesting relationships between the other features (not the main feature(s) of interest)?\n",
    "\n",
    "> Your answer here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate Exploration\n",
    "\n",
    "> Create plots of three or more variables to investigate your data even\n",
    "further. Make sure that your investigations are justified, and follow from\n",
    "your work in the previous sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Talk about some of the relationships you observed in this part of the investigation. Were there features that strengthened each other in terms of looking at your feature(s) of interest?\n",
    "\n",
    "> Your answer here!\n",
    "\n",
    "### Were there any interesting or surprising interactions between features?\n",
    "\n",
    "> Your answer here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> At the end of your report, make sure that you export the notebook as an\n",
    "html file from the `File > Download as... > HTML` menu. Make sure you keep\n",
    "track of where the exported file goes, so you can put it in the same folder\n",
    "as this notebook for project submission. Also, make sure you remove all of\n",
    "the quote-formatted guide notes like this one before you finish your report!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
